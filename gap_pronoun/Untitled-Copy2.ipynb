{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# This variable is used by helperbot to make the training deterministic\n",
    "os.environ[\"SEED\"] = \"33223\"\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertModel\n",
    "\n",
    "from helperbot import BaseBot, TriangularLR\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL = 'bert-large-uncased'\n",
    "CASED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"gap-test.tsv\", delimiter=\"\\t\")\n",
    "df_val = pd.read_csv(\"gap-validation.tsv\", delimiter=\"\\t\")\n",
    "df_test = pd.read_csv(\"gap-development.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    BERT_MODEL,\n",
    "    do_lower_case=CASED,\n",
    "    never_split = (\"[UNK]\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\", \"[A]\", \"[B]\", \"[P]\")\n",
    ")\n",
    "# These tokens are not actually used, so we can assign arbitrary values.\n",
    "tokenizer.vocab[\"[A]\"] = -1\n",
    "tokenizer.vocab[\"[B]\"] = -1\n",
    "tokenizer.vocab[\"[P]\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = GAPDataset(df_train, tokenizer)\n",
    "val_ds = GAPDataset(df_val, tokenizer)\n",
    "test_ds = GAPDataset(df_test, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    collate_fn = collate_examples,\n",
    "    batch_size=20,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    collate_fn = collate_examples,\n",
    "    batch_size=128,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    collate_fn = collate_examples,\n",
    "    batch_size=128,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 1248501532/1248501532 [06:45<00:00, 3080577.69B/s]\n"
     ]
    }
   ],
   "source": [
    "model = GAPModel(BERT_MODEL, torch.device(\"cuda:0\"))\n",
    "# You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
    "set_trainable(model.bert, False)\n",
    "set_trainable(model.head, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[03/31/2019 04:39:06 AM]] SEED: 33223\n",
      "[[03/31/2019 04:39:06 AM]] # of paramters: 336,723,971\n",
      "[[03/31/2019 04:39:06 AM]] # of trainable paramters: 1,582,083\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "bot = GAPBot(\n",
    "    model, train_loader, val_loader,\n",
    "    optimizer=optimizer, echo=True,\n",
    "    avg_window=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[03/31/2019 04:39:08 AM]] Optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "[[03/31/2019 04:39:08 AM]] Batches per epoch: 100\n",
      "[[03/31/2019 04:39:08 AM]] ====================Epoch 1====================\n",
      "[[03/31/2019 04:39:14 AM]] Step 25: train 1.853466 lr: 1.816e-04\n",
      "[[03/31/2019 04:39:20 AM]] Step 50: train 1.697854 lr: 3.247e-04\n",
      "[[03/31/2019 04:39:25 AM]] Step 75: train 1.579227 lr: 4.678e-04\n",
      "[[03/31/2019 04:39:30 AM]] Step 100: train 1.516384 lr: 6.108e-04\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.30s/it]\n",
      "[[03/31/2019 04:39:36 AM]] Snapshot loss 0.894100\n",
      "[[03/31/2019 04:39:48 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[03/31/2019 04:39:48 AM]] New low\n",
      "\n",
      "[[03/31/2019 04:39:48 AM]] ====================Epoch 2====================\n",
      "[[03/31/2019 04:39:54 AM]] Step 125: train 1.439029 lr: 7.539e-04\n",
      "[[03/31/2019 04:39:59 AM]] Step 150: train 1.362474 lr: 8.970e-04\n",
      "[[03/31/2019 04:40:04 AM]] Step 175: train 1.353909 lr: 9.801e-04\n",
      "[[03/31/2019 04:40:09 AM]] Step 200: train 1.297870 lr: 9.090e-04\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.28s/it]\n",
      "[[03/31/2019 04:40:15 AM]] Snapshot loss 0.753561\n",
      "[[03/31/2019 04:40:27 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[03/31/2019 04:40:27 AM]] New low\n",
      "\n",
      "[[03/31/2019 04:40:27 AM]] ====================Epoch 3====================\n",
      "[[03/31/2019 04:40:32 AM]] Step 225: train 1.246538 lr: 8.379e-04\n",
      "[[03/31/2019 04:40:37 AM]] Step 250: train 1.212454 lr: 7.668e-04\n",
      "[[03/31/2019 04:40:43 AM]] Step 275: train 1.174305 lr: 6.957e-04\n",
      "[[03/31/2019 04:40:48 AM]] Step 300: train 1.147016 lr: 6.246e-04\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.28s/it]\n",
      "[[03/31/2019 04:40:53 AM]] Snapshot loss 0.715355\n",
      "[[03/31/2019 04:41:05 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[03/31/2019 04:41:05 AM]] New low\n",
      "\n",
      "[[03/31/2019 04:41:05 AM]] ====================Epoch 4====================\n",
      "[[03/31/2019 04:41:10 AM]] Step 325: train 1.053644 lr: 5.534e-04\n",
      "[[03/31/2019 04:41:16 AM]] Step 350: train 0.982650 lr: 4.823e-04\n",
      "[[03/31/2019 04:41:21 AM]] Step 375: train 0.927609 lr: 4.112e-04\n",
      "[[03/31/2019 04:41:26 AM]] Step 400: train 0.883303 lr: 3.401e-04\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.28s/it]\n",
      "[[03/31/2019 04:41:32 AM]] Snapshot loss 0.630633\n",
      "[[03/31/2019 04:41:44 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[03/31/2019 04:41:44 AM]] New low\n",
      "\n",
      "[[03/31/2019 04:41:44 AM]] ====================Epoch 5====================\n",
      "[[03/31/2019 04:41:49 AM]] Step 425: train 0.837717 lr: 2.690e-04\n",
      "[[03/31/2019 04:41:54 AM]] Step 450: train 0.806321 lr: 1.979e-04\n",
      "[[03/31/2019 04:42:00 AM]] Step 475: train 0.747420 lr: 1.268e-04\n",
      "[[03/31/2019 04:42:05 AM]] Step 500: train 0.733745 lr: 5.569e-05\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.28s/it]\n",
      "[[03/31/2019 04:42:10 AM]] Snapshot loss 0.599178\n",
      "[[03/31/2019 04:42:22 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[03/31/2019 04:42:22 AM]] New low\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = len(train_loader) \n",
    "n_steps = steps_per_epoch * 5\n",
    "bot.train(\n",
    "    n_steps,\n",
    "    log_interval=steps_per_epoch // 4,\n",
    "    snapshot_interval=steps_per_epoch,\n",
    "    scheduler=TriangularLR(\n",
    "        optimizer, 20, ratio=2, steps_per_cycle=n_steps)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.load_model(\"./cache/model_cache/best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(bot.model.state_dict(), \"./cache/model_cache/best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:24<00:00,  1.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.550768973827362"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the test dataset\n",
    "bot.eval(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:24<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract predictions to the test dataset\n",
    "preds = bot.predict(test_loader,return_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9115, -0.1810, -1.3243],\n",
       "         [ 4.3801, -4.1799, -2.0921],\n",
       "         [-1.9990,  1.1068,  1.9490],\n",
       "         ...,\n",
       "         [ 2.2471,  1.4013,  0.7029],\n",
       "         [ 6.9068, -4.2859, -1.9861],\n",
       "         [-0.7334,  1.0151,  0.3522]]), tensor([0, 0, 1,  ..., 0, 0, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = torch.max(preds[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "155\n",
      "162\n",
      "166\n",
      "155\n",
      "167\n",
      "151\n",
      "165\n",
      "160\n",
      "154\n",
      "0.796\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "for i in range(1, 11):\n",
    "    count = sum(labels[(i-1)*200:i*200] == preds[1][(i-1)*200:i*200])\n",
    "    print(count.item())\n",
    "    total_count += count.item()\n",
    "print(total_count*1.0/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inference = pd.read_csv(\"inference.tsv\", delimiter=\"\\t\")\n",
    "inference_ds = GAPDataset(df_inference, tokenizer)\n",
    "inference_loader = DataLoader(\n",
    "    inference_ds,\n",
    "    collate_fn = collate_examples,\n",
    "    batch_size=128,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.36622440814971924"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.eval(inference_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = bot.predict(inference_loader,return_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9115, -0.1810, -1.3243]]), tensor([0]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = torch.max(preds[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0]), tensor([0]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
