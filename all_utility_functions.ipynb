{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import pprint as pprint\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_DIR = \"processed_data\"\n",
    "MODEL_NAME = \"BERT_Attention\"\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device) \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(passage_text):\n",
    "    passage_text_processed = nlp(passage_text)\n",
    "    passage_with_separators = ' '.join(['[CLS]'] + [sent.text + ' [SEP]' for sent in passage_text_processed.sents])\n",
    "    passage_with_separators_tokenized = tokenizer.tokenize(passage_with_separators)    \n",
    "    model.eval()\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(passage_with_separators_tokenized)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor)\n",
    "\n",
    "    indices = [i for i, w in enumerate(passage_with_separators_tokenized) if (w not in ['[CLS]', '[SEP]'])]\n",
    "    nonseparator_tokens = [w for i, w in enumerate(passage_with_separators_tokenized) if (w not in ['[CLS]', '[SEP]'])]\n",
    "    nonseparators = torch.squeeze(encoded_layers[-1])[indices][:]\n",
    "\n",
    "    attn_vectors_per_word = []\n",
    "    encountered_words = []\n",
    "    i = 0\n",
    "    carry_over = None\n",
    "    had_carry_over = False\n",
    "    \n",
    "    for w_i, word in enumerate(passage_text_processed):\n",
    "        word = word.text.lower()\n",
    "        first_attention_vector = nonseparators[i]\n",
    "        current_word = ''\n",
    "        if word == ' ':\n",
    "            attn_vectors_per_word.append(first_attention_vector)\n",
    "            continue\n",
    "        if carry_over:\n",
    "            current_word = carry_over\n",
    "            carry_over = None\n",
    "        while current_word[:len(word)] != word:\n",
    "            current_token = nonseparator_tokens[i]\n",
    "            current_word += (current_token if (current_token[:2] != '##') else current_token[2:])\n",
    "            i += 1\n",
    "        encountered_words.append(current_word)\n",
    "        if not had_carry_over:\n",
    "            attn_vectors_per_word.append(first_attention_vector)\n",
    "        else:\n",
    "            had_carry_over = False\n",
    "        if len(current_word) > len(word):\n",
    "            attn_vectors_per_word.append(first_attention_vector)\n",
    "            carry_over = current_word[len(word):]\n",
    "            had_carry_over = True\n",
    "    output = torch.stack(attn_vectors_per_word)\n",
    "    assert len([word for word in passage_text_processed]) == len(attn_vectors_per_word)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_featues_from_pairs(X_batch, embeddings):\n",
    "    batch_embeddings = []\n",
    "    for x in X_batch:\n",
    "        doc_id, a_start, a_end, b_start, b_end = x \n",
    "        doc_emb = embeddings[doc_id]\n",
    "        emb_a = torch.sum(doc_emb[a_start:a_end+1], 0)\n",
    "        emb_b = torch.sum(doc_emb[b_start:b_end+1], 0)\n",
    "        emb_dot = torch.mul(emb_a, emb_a)\n",
    "        emb_cat   = torch.cat((emb_a, emb_b), 0)\n",
    "        emb   = torch.cat((emb_cat, emb_dot), 0)\n",
    "        batch_embeddings.append(emb)\n",
    "    return torch.stack(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, criterion, batch_size, X_data, Y_data, embeddings, mode=\"train\"):\n",
    "    \n",
    "    if(mode == \"train\"):\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    running_corrects = 0\n",
    "    shuffled_idx = list(np.random.permutation(len(X_data)))\n",
    "    minibatch_idxs = np.array_split(shuffled_idx, len(shuffled_idx)/batch_size) \n",
    "    ones = 0\n",
    "    zeros = 0\n",
    "    for minibatch_ids in minibatch_idxs:\n",
    "        x_batch_raw = X_data[minibatch_ids]\n",
    "        x_batch = get_featues_from_pairs(x_batch_raw, embeddings)\n",
    "        y_batch = torch.tensor(Y_data[minibatch_ids]).type(torch.float32)\n",
    "        x_batch = Variable(x_batch).to(device)\n",
    "        y_batch = Variable(y_batch).to(device)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        if(mode == \"train\"):\n",
    "            y_hat = model(x_batch)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                y_hat = model(x_batch)\n",
    "        \n",
    "        y_preds = (y_hat > 0.7).type(torch.float32)\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        corrects = float(torch.sum(y_preds == y_batch).item())\n",
    "        running_corrects += corrects\n",
    "        ones  += torch.sum(y_preds==1).item()\n",
    "        zeros +=  torch.sum(y_preds==0).item()\n",
    "        if(mode == \"train\"):\n",
    "            loss.backward()\n",
    "            opt.step()    \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    print(\"ones and zeros\", ones, zeros)\n",
    "    accuracy = running_corrects * 1.0 / len(shuffled_idx)\n",
    "    avg_loss = sum(losses) * 1.0 / len(losses)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, embeddings, batch_size=256):\n",
    "    model.eval()\n",
    "    idxs = range(0, len(X))\n",
    "    minibatch_idxs = np.array_split(idxs, len(idxs)/min(batch_size,len(idxs)))\n",
    "    y_preds_all = torch.Tensor().to(device)\n",
    "    y_hats_all = torch.Tensor().to(device)\n",
    "    for minibatch_ids in minibatch_idxs:\n",
    "        x_batch_raw = X[minibatch_ids]\n",
    "        x_batch = get_featues_from_pairs(x_batch_raw, embeddings)\n",
    "        x_batch = Variable(x_batch).to(device)\n",
    "        with torch.no_grad():\n",
    "                y_hats = model(x_batch)\n",
    "        y_preds = (y_hats > 0.7).type(torch.float32)\n",
    "        y_preds_all = torch.cat((y_preds_all,y_preds))\n",
    "        y_hats_all = torch.cat((y_preds_all,y_hats))\n",
    "    return y_preds_all, y_hats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, embeddings):\n",
    "    y_preds, y_hats = predict(model, X, embeddings)\n",
    "    Y = Variable(torch.tensor(Y).type(torch.float32)).to(device)\n",
    "    corrects = float(torch.sum(y_preds == Y).item())\n",
    "    accuracy = corrects * 1.0 / Y.size()[0]\n",
    "    return accuracy,y_preds, y_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(768*3, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout = self.dout(h1)\n",
    "        a2 = self.fc2(dout)\n",
    "        h2 = self.relu2(a2)\n",
    "        a3 = self.out(h2)\n",
    "        y = self.out_act(a3)\n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
