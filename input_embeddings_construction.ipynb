{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import pprint as pprint\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_DIR = \"processed_data\"\n",
    "MODEL_NAME = \"BERT_Attention\"\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device) \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(passage_text):\n",
    "    passage_text_processed = nlp(passage_text)\n",
    "    passage_with_separators = ' '.join(['[CLS]'] + [sent.text + ' [SEP]' for sent in passage_text_processed.sents])\n",
    "    passage_with_separators_tokenized = tokenizer.tokenize(passage_with_separators)    \n",
    "    model.eval()\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(passage_with_separators_tokenized)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor)\n",
    "\n",
    "    indices = [i for i, w in enumerate(passage_with_separators_tokenized) if (w not in ['[CLS]', '[SEP]'])]\n",
    "    nonseparator_tokens = [w for i, w in enumerate(passage_with_separators_tokenized) if (w not in ['[CLS]', '[SEP]'])]\n",
    "    nonseparators = torch.squeeze(encoded_layers[-1])[indices][:]\n",
    "\n",
    "    attn_vectors_per_word = []\n",
    "    encountered_words = []\n",
    "    i = 0\n",
    "    carry_over = None\n",
    "    had_carry_over = False\n",
    "    \n",
    "    for w_i, word in enumerate(passage_text_processed):\n",
    "        word = word.text.lower()\n",
    "        first_attention_vector = nonseparators[i]\n",
    "        current_word = ''\n",
    "        if word == ' ':\n",
    "            attn_vectors_per_word.append(first_attention_vector)\n",
    "            continue\n",
    "        if carry_over:\n",
    "            current_word = carry_over\n",
    "            carry_over = None\n",
    "        while current_word[:len(word)] != word:\n",
    "            current_token = nonseparator_tokens[i]\n",
    "            current_word += (current_token if (current_token[:2] != '##') else current_token[2:])\n",
    "            i += 1\n",
    "        encountered_words.append(current_word)\n",
    "        if not had_carry_over:\n",
    "            attn_vectors_per_word.append(first_attention_vector)\n",
    "        else:\n",
    "            had_carry_over = False\n",
    "        if len(current_word) > len(word):\n",
    "            attn_vectors_per_word.append(first_attention_vector)\n",
    "            carry_over = current_word[len(word):]\n",
    "            had_carry_over = True\n",
    "    output = torch.stack(attn_vectors_per_word)\n",
    "    assert len([word for word in passage_text_processed]) == len(attn_vectors_per_word)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_passages = np.load(\"processed_data/train_passage_list.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing doc 0\n",
      "processing doc 1\n",
      "processing doc 2\n",
      "processing doc 3\n",
      "processing doc 4\n",
      "processing doc 5\n",
      "processing doc 6\n",
      "processing doc 7\n",
      "processing doc 8\n",
      "processing doc 9\n",
      "processing doc 10\n",
      "processing doc 11\n",
      "processing doc 12\n",
      "processing doc 13\n",
      "processing doc 14\n",
      "processing doc 15\n",
      "processing doc 16\n",
      "processing doc 17\n",
      "processing doc 18\n",
      "processing doc 19\n",
      "processing doc 20\n",
      "processing doc 21\n",
      "processing doc 22\n",
      "processing doc 23\n",
      "processing doc 24\n",
      "processing doc 25\n",
      "processing doc 26\n",
      "processing doc 27\n",
      "processing doc 28\n",
      "processing doc 29\n",
      "processing doc 30\n",
      "processing doc 31\n",
      "processing doc 32\n",
      "processing doc 33\n",
      "processing doc 34\n",
      "processing doc 35\n",
      "processing doc 36\n",
      "processing doc 37\n",
      "processing doc 38\n",
      "processing doc 39\n",
      "processing doc 40\n",
      "processing doc 41\n",
      "processing doc 42\n",
      "processing doc 43\n",
      "processing doc 44\n",
      "processing doc 45\n",
      "processing doc 46\n",
      "processing doc 47\n",
      "processing doc 48\n",
      "processing doc 49\n",
      "processing doc 50\n",
      "processing doc 51\n",
      "processing doc 52\n",
      "processing doc 53\n",
      "processing doc 54\n",
      "processing doc 55\n",
      "processing doc 56\n",
      "processing doc 57\n",
      "processing doc 58\n",
      "processing doc 59\n",
      "processing doc 60\n",
      "processing doc 61\n",
      "processing doc 62\n",
      "processing doc 63\n",
      "processing doc 64\n",
      "processing doc 65\n",
      "processing doc 66\n",
      "processing doc 67\n",
      "processing doc 68\n",
      "processing doc 69\n",
      "processing doc 70\n",
      "processing doc 71\n",
      "processing doc 72\n",
      "processing doc 73\n",
      "processing doc 74\n",
      "processing doc 75\n",
      "processing doc 76\n",
      "processing doc 77\n",
      "processing doc 78\n",
      "processing doc 79\n",
      "processing doc 80\n",
      "processing doc 81\n",
      "processing doc 82\n",
      "processing doc 83\n",
      "processing doc 84\n",
      "processing doc 85\n",
      "processing doc 86\n",
      "processing doc 87\n",
      "processing doc 88\n",
      "processing doc 89\n",
      "processing doc 90\n",
      "processing doc 91\n",
      "processing doc 92\n",
      "processing doc 93\n",
      "processing doc 94\n",
      "processing doc 95\n",
      "processing doc 96\n",
      "processing doc 97\n",
      "processing doc 98\n",
      "processing doc 99\n",
      "processing doc 100\n",
      "processing doc 101\n",
      "processing doc 102\n",
      "processing doc 103\n",
      "processing doc 104\n",
      "processing doc 105\n",
      "processing doc 106\n",
      "processing doc 107\n",
      "processing doc 108\n",
      "processing doc 109\n",
      "processing doc 110\n",
      "processing doc 111\n",
      "processing doc 112\n",
      "processing doc 113\n",
      "processing doc 114\n",
      "processing doc 115\n",
      "processing doc 116\n",
      "processing doc 117\n",
      "processing doc 118\n",
      "processing doc 119\n",
      "processing doc 120\n",
      "processing doc 121\n",
      "processing doc 122\n",
      "processing doc 123\n",
      "processing doc 124\n",
      "processing doc 125\n",
      "processing doc 126\n",
      "processing doc 127\n",
      "processing doc 128\n",
      "processing doc 129\n",
      "processing doc 130\n",
      "processing doc 131\n",
      "processing doc 132\n",
      "processing doc 133\n",
      "processing doc 134\n",
      "processing doc 135\n",
      "processing doc 136\n",
      "processing doc 137\n",
      "processing doc 138\n",
      "processing doc 139\n",
      "processing doc 140\n",
      "processing doc 141\n",
      "processing doc 142\n",
      "processing doc 143\n",
      "processing doc 144\n",
      "processing doc 145\n",
      "processing doc 146\n",
      "processing doc 147\n",
      "processing doc 148\n",
      "processing doc 149\n",
      "processing doc 150\n",
      "processing doc 151\n",
      "processing doc 152\n",
      "processing doc 153\n",
      "processing doc 154\n",
      "processing doc 155\n",
      "processing doc 156\n",
      "processing doc 157\n",
      "processing doc 158\n",
      "processing doc 159\n",
      "processing doc 160\n",
      "processing doc 161\n",
      "processing doc 162\n",
      "processing doc 163\n",
      "processing doc 164\n",
      "processing doc 165\n",
      "processing doc 166\n",
      "processing doc 167\n",
      "processing doc 168\n",
      "processing doc 169\n",
      "processing doc 170\n",
      "processing doc 171\n",
      "processing doc 172\n",
      "processing doc 173\n",
      "processing doc 174\n",
      "processing doc 175\n",
      "processing doc 176\n",
      "processing doc 177\n",
      "processing doc 178\n",
      "processing doc 179\n",
      "processing doc 180\n",
      "processing doc 181\n",
      "processing doc 182\n",
      "processing doc 183\n",
      "processing doc 184\n",
      "processing doc 185\n",
      "processing doc 186\n",
      "processing doc 187\n",
      "processing doc 188\n",
      "processing doc 189\n",
      "processing doc 190\n",
      "processing doc 191\n",
      "processing doc 192\n",
      "processing doc 193\n",
      "processing doc 194\n",
      "processing doc 195\n",
      "processing doc 196\n",
      "processing doc 197\n",
      "processing doc 198\n",
      "processing doc 199\n",
      "processing doc 200\n",
      "processing doc 201\n",
      "processing doc 202\n",
      "processing doc 203\n",
      "processing doc 204\n",
      "processing doc 205\n",
      "processing doc 206\n",
      "processing doc 207\n",
      "processing doc 208\n",
      "processing doc 209\n",
      "processing doc 210\n",
      "processing doc 211\n",
      "processing doc 212\n",
      "processing doc 213\n",
      "processing doc 214\n",
      "processing doc 215\n",
      "processing doc 216\n",
      "processing doc 217\n",
      "processing doc 218\n",
      "processing doc 219\n",
      "processing doc 220\n",
      "processing doc 221\n",
      "processing doc 222\n",
      "processing doc 223\n",
      "processing doc 224\n",
      "processing doc 225\n",
      "processing doc 226\n",
      "processing doc 227\n",
      "processing doc 228\n",
      "processing doc 229\n",
      "processing doc 230\n",
      "processing doc 231\n",
      "processing doc 232\n",
      "processing doc 233\n",
      "processing doc 234\n",
      "processing doc 235\n",
      "processing doc 236\n",
      "processing doc 237\n",
      "processing doc 238\n",
      "processing doc 239\n",
      "processing doc 240\n",
      "processing doc 241\n",
      "processing doc 242\n",
      "processing doc 243\n",
      "processing doc 244\n",
      "processing doc 245\n",
      "processing doc 246\n",
      "processing doc 247\n",
      "processing doc 248\n",
      "processing doc 249\n",
      "processing doc 250\n",
      "processing doc 251\n",
      "processing doc 252\n",
      "processing doc 253\n",
      "processing doc 254\n",
      "processing doc 255\n",
      "processing doc 256\n",
      "processing doc 257\n",
      "processing doc 258\n",
      "processing doc 259\n",
      "processing doc 260\n",
      "processing doc 261\n",
      "processing doc 262\n",
      "processing doc 263\n",
      "processing doc 264\n",
      "processing doc 265\n",
      "processing doc 266\n",
      "processing doc 267\n",
      "processing doc 268\n",
      "processing doc 269\n",
      "processing doc 270\n",
      "processing doc 271\n",
      "processing doc 272\n",
      "processing doc 273\n",
      "processing doc 274\n",
      "processing doc 275\n",
      "processing doc 276\n",
      "processing doc 277\n",
      "processing doc 278\n",
      "processing doc 279\n",
      "processing doc 280\n",
      "processing doc 281\n",
      "processing doc 282\n",
      "processing doc 283\n",
      "processing doc 284\n",
      "processing doc 285\n",
      "processing doc 286\n",
      "processing doc 287\n",
      "processing doc 288\n",
      "processing doc 289\n",
      "processing doc 290\n",
      "processing doc 291\n",
      "processing doc 292\n",
      "processing doc 293\n",
      "processing doc 294\n",
      "processing doc 295\n",
      "processing doc 296\n",
      "processing doc 297\n",
      "processing doc 298\n",
      "processing doc 299\n",
      "processing doc 300\n",
      "processing doc 301\n",
      "processing doc 302\n",
      "processing doc 303\n",
      "processing doc 304\n",
      "processing doc 305\n",
      "processing doc 306\n",
      "processing doc 307\n",
      "processing doc 308\n",
      "processing doc 309\n",
      "processing doc 310\n",
      "processing doc 311\n",
      "processing doc 312\n",
      "processing doc 313\n",
      "processing doc 314\n",
      "processing doc 315\n",
      "processing doc 316\n",
      "processing doc 317\n",
      "processing doc 318\n",
      "processing doc 319\n",
      "processing doc 320\n",
      "processing doc 321\n",
      "processing doc 322\n",
      "processing doc 323\n",
      "processing doc 324\n",
      "processing doc 325\n",
      "processing doc 326\n",
      "processing doc 327\n",
      "processing doc 328\n",
      "processing doc 329\n",
      "processing doc 330\n",
      "processing doc 331\n",
      "processing doc 332\n",
      "processing doc 333\n",
      "processing doc 334\n",
      "processing doc 335\n",
      "processing doc 336\n",
      "processing doc 337\n",
      "processing doc 338\n",
      "processing doc 339\n",
      "processing doc 340\n",
      "processing doc 341\n",
      "processing doc 342\n",
      "processing doc 343\n",
      "processing doc 344\n",
      "processing doc 345\n",
      "processing doc 346\n",
      "processing doc 347\n",
      "processing doc 348\n",
      "processing doc 349\n",
      "processing doc 350\n",
      "processing doc 351\n",
      "processing doc 352\n",
      "processing doc 353\n",
      "processing doc 354\n",
      "processing doc 355\n",
      "processing doc 356\n",
      "processing doc 357\n",
      "processing doc 358\n",
      "processing doc 359\n",
      "processing doc 360\n",
      "processing doc 361\n",
      "processing doc 362\n",
      "processing doc 363\n",
      "processing doc 364\n",
      "processing doc 365\n",
      "processing doc 366\n",
      "processing doc 367\n",
      "processing doc 368\n",
      "processing doc 369\n",
      "processing doc 370\n",
      "processing doc 371\n",
      "processing doc 372\n",
      "processing doc 373\n",
      "processing doc 374\n",
      "processing doc 375\n",
      "processing doc 376\n",
      "processing doc 377\n",
      "processing doc 378\n",
      "processing doc 379\n",
      "processing doc 380\n",
      "processing doc 381\n",
      "processing doc 382\n",
      "processing doc 383\n",
      "processing doc 384\n",
      "processing doc 385\n",
      "processing doc 386\n",
      "processing doc 387\n",
      "processing doc 388\n",
      "processing doc 389\n",
      "processing doc 390\n",
      "processing doc 391\n",
      "processing doc 392\n",
      "processing doc 393\n",
      "processing doc 394\n",
      "processing doc 395\n",
      "processing doc 396\n",
      "processing doc 397\n",
      "processing doc 398\n",
      "processing doc 399\n",
      "processing doc 400\n",
      "processing doc 401\n",
      "processing doc 402\n",
      "processing doc 403\n",
      "processing doc 404\n",
      "processing doc 405\n",
      "processing doc 406\n",
      "processing doc 407\n",
      "processing doc 408\n",
      "processing doc 409\n",
      "processing doc 410\n",
      "processing doc 411\n",
      "processing doc 412\n",
      "processing doc 413\n",
      "processing doc 414\n",
      "processing doc 415\n",
      "processing doc 416\n",
      "processing doc 417\n",
      "processing doc 418\n",
      "processing doc 419\n",
      "processing doc 420\n",
      "processing doc 421\n",
      "processing doc 422\n",
      "processing doc 423\n",
      "processing doc 424\n",
      "processing doc 425\n",
      "processing doc 426\n",
      "processing doc 427\n",
      "processing doc 428\n",
      "processing doc 429\n",
      "processing doc 430\n",
      "processing doc 431\n",
      "processing doc 432\n",
      "processing doc 433\n",
      "processing doc 434\n",
      "processing doc 435\n",
      "processing doc 436\n",
      "processing doc 437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing doc 438\n",
      "processing doc 439\n",
      "processing doc 440\n",
      "processing doc 441\n",
      "processing doc 442\n",
      "processing doc 443\n",
      "processing doc 444\n",
      "processing doc 445\n",
      "processing doc 446\n",
      "processing doc 447\n",
      "processing doc 448\n",
      "processing doc 449\n",
      "processing doc 450\n",
      "processing doc 451\n",
      "processing doc 452\n",
      "processing doc 453\n",
      "processing doc 454\n",
      "processing doc 455\n",
      "processing doc 456\n",
      "processing doc 457\n",
      "processing doc 458\n",
      "processing doc 459\n",
      "processing doc 460\n",
      "processing doc 461\n",
      "processing doc 462\n",
      "processing doc 463\n",
      "processing doc 464\n",
      "processing doc 465\n",
      "processing doc 466\n",
      "processing doc 467\n",
      "processing doc 468\n",
      "processing doc 469\n",
      "processing doc 470\n",
      "processing doc 471\n",
      "processing doc 472\n",
      "processing doc 473\n",
      "processing doc 474\n",
      "processing doc 475\n",
      "processing doc 476\n",
      "processing doc 477\n",
      "processing doc 478\n",
      "processing doc 479\n",
      "processing doc 480\n",
      "processing doc 481\n",
      "processing doc 482\n",
      "processing doc 483\n",
      "processing doc 484\n",
      "processing doc 485\n",
      "processing doc 486\n",
      "processing doc 487\n",
      "processing doc 488\n",
      "processing doc 489\n",
      "processing doc 490\n",
      "processing doc 491\n",
      "processing doc 492\n",
      "processing doc 493\n",
      "processing doc 494\n",
      "processing doc 495\n",
      "processing doc 496\n",
      "processing doc 497\n",
      "processing doc 498\n",
      "processing doc 499\n",
      "processing doc 500\n",
      "processing doc 501\n",
      "processing doc 502\n",
      "processing doc 503\n",
      "processing doc 504\n",
      "processing doc 505\n",
      "processing doc 506\n",
      "processing doc 507\n",
      "processing doc 508\n",
      "processing doc 509\n",
      "processing doc 510\n",
      "processing doc 511\n",
      "processing doc 512\n",
      "processing doc 513\n",
      "processing doc 514\n",
      "processing doc 515\n",
      "processing doc 516\n",
      "processing doc 517\n",
      "processing doc 518\n",
      "processing doc 519\n",
      "processing doc 520\n",
      "processing doc 521\n",
      "processing doc 522\n",
      "processing doc 523\n",
      "processing doc 524\n",
      "processing doc 525\n",
      "processing doc 526\n",
      "processing doc 527\n",
      "processing doc 528\n",
      "processing doc 529\n",
      "processing doc 530\n",
      "processing doc 531\n",
      "processing doc 532\n",
      "processing doc 533\n",
      "processing doc 534\n",
      "processing doc 535\n",
      "processing doc 536\n",
      "processing doc 537\n",
      "processing doc 538\n",
      "processing doc 539\n",
      "processing doc 540\n",
      "processing doc 541\n",
      "processing doc 542\n",
      "processing doc 543\n",
      "processing doc 544\n",
      "processing doc 545\n",
      "processing doc 546\n",
      "processing doc 547\n",
      "processing doc 548\n",
      "processing doc 549\n",
      "processing doc 550\n",
      "processing doc 551\n",
      "processing doc 552\n",
      "processing doc 553\n",
      "processing doc 554\n",
      "processing doc 555\n",
      "processing doc 556\n",
      "processing doc 557\n",
      "processing doc 558\n",
      "processing doc 559\n",
      "processing doc 560\n",
      "processing doc 561\n",
      "processing doc 562\n",
      "processing doc 563\n",
      "processing doc 564\n",
      "processing doc 565\n",
      "processing doc 566\n",
      "processing doc 567\n",
      "processing doc 568\n",
      "processing doc 569\n",
      "processing doc 570\n",
      "processing doc 571\n",
      "processing doc 572\n",
      "processing doc 573\n",
      "processing doc 574\n",
      "processing doc 575\n",
      "processing doc 576\n",
      "processing doc 577\n",
      "processing doc 578\n",
      "processing doc 579\n",
      "processing doc 580\n",
      "processing doc 581\n",
      "processing doc 582\n",
      "processing doc 583\n",
      "processing doc 584\n",
      "processing doc 585\n",
      "processing doc 586\n",
      "processing doc 587\n",
      "processing doc 588\n",
      "processing doc 589\n",
      "processing doc 590\n",
      "processing doc 591\n",
      "processing doc 592\n",
      "processing doc 593\n",
      "processing doc 594\n",
      "processing doc 595\n",
      "processing doc 596\n",
      "processing doc 597\n",
      "processing doc 598\n",
      "processing doc 599\n",
      "processing doc 600\n",
      "processing doc 601\n",
      "processing doc 602\n",
      "processing doc 603\n",
      "processing doc 604\n",
      "processing doc 605\n",
      "processing doc 606\n",
      "processing doc 607\n",
      "processing doc 608\n",
      "processing doc 609\n",
      "processing doc 610\n",
      "processing doc 611\n",
      "processing doc 612\n",
      "processing doc 613\n",
      "processing doc 614\n",
      "processing doc 615\n",
      "processing doc 616\n",
      "processing doc 617\n",
      "processing doc 618\n",
      "processing doc 619\n",
      "processing doc 620\n",
      "processing doc 621\n",
      "processing doc 622\n",
      "processing doc 623\n",
      "processing doc 624\n",
      "processing doc 625\n",
      "processing doc 626\n",
      "processing doc 627\n",
      "processing doc 628\n",
      "processing doc 629\n",
      "processing doc 630\n",
      "processing doc 631\n",
      "processing doc 632\n",
      "processing doc 633\n",
      "processing doc 634\n",
      "processing doc 635\n",
      "processing doc 636\n",
      "processing doc 637\n",
      "processing doc 638\n",
      "processing doc 639\n",
      "processing doc 640\n",
      "processing doc 641\n",
      "processing doc 642\n",
      "processing doc 643\n",
      "processing doc 644\n",
      "processing doc 645\n",
      "processing doc 646\n",
      "processing doc 647\n",
      "processing doc 648\n",
      "processing doc 649\n",
      "processing doc 650\n",
      "processing doc 651\n",
      "processing doc 652\n",
      "processing doc 653\n",
      "processing doc 654\n",
      "processing doc 655\n",
      "processing doc 656\n",
      "processing doc 657\n",
      "processing doc 658\n",
      "processing doc 659\n",
      "processing doc 660\n",
      "processing doc 661\n",
      "processing doc 662\n",
      "processing doc 663\n",
      "processing doc 664\n",
      "processing doc 665\n",
      "processing doc 666\n",
      "processing doc 667\n",
      "processing doc 668\n",
      "processing doc 669\n",
      "processing doc 670\n",
      "processing doc 671\n",
      "processing doc 672\n",
      "processing doc 673\n",
      "processing doc 674\n",
      "processing doc 675\n",
      "processing doc 676\n",
      "processing doc 677\n",
      "processing doc 678\n",
      "processing doc 679\n",
      "processing doc 680\n",
      "processing doc 681\n",
      "processing doc 682\n",
      "processing doc 683\n",
      "processing doc 684\n",
      "processing doc 685\n",
      "processing doc 686\n",
      "processing doc 687\n",
      "processing doc 688\n",
      "processing doc 689\n",
      "processing doc 690\n",
      "processing doc 691\n",
      "processing doc 692\n",
      "processing doc 693\n",
      "processing doc 694\n",
      "processing doc 695\n",
      "processing doc 696\n",
      "processing doc 697\n",
      "processing doc 698\n",
      "processing doc 699\n",
      "processing doc 700\n",
      "processing doc 701\n",
      "processing doc 702\n",
      "processing doc 703\n",
      "processing doc 704\n",
      "processing doc 705\n",
      "processing doc 706\n",
      "processing doc 707\n",
      "processing doc 708\n",
      "processing doc 709\n",
      "processing doc 710\n",
      "processing doc 711\n",
      "processing doc 712\n",
      "processing doc 713\n",
      "processing doc 714\n",
      "processing doc 715\n",
      "processing doc 716\n",
      "processing doc 717\n",
      "processing doc 718\n",
      "processing doc 719\n",
      "processing doc 720\n",
      "processing doc 721\n",
      "processing doc 722\n",
      "processing doc 723\n",
      "processing doc 724\n",
      "processing doc 725\n",
      "processing doc 726\n",
      "processing doc 727\n",
      "processing doc 728\n",
      "processing doc 729\n",
      "processing doc 730\n",
      "processing doc 731\n",
      "processing doc 732\n",
      "processing doc 733\n",
      "processing doc 734\n",
      "processing doc 735\n",
      "processing doc 736\n",
      "processing doc 737\n",
      "processing doc 738\n",
      "processing doc 739\n",
      "processing doc 740\n",
      "processing doc 741\n",
      "processing doc 742\n",
      "processing doc 743\n",
      "processing doc 744\n",
      "processing doc 745\n",
      "processing doc 746\n",
      "processing doc 747\n",
      "processing doc 748\n",
      "processing doc 749\n",
      "processing doc 750\n",
      "processing doc 751\n",
      "processing doc 752\n",
      "processing doc 753\n",
      "processing doc 754\n",
      "processing doc 755\n",
      "processing doc 756\n",
      "processing doc 757\n",
      "processing doc 758\n",
      "processing doc 759\n",
      "processing doc 760\n",
      "processing doc 761\n",
      "processing doc 762\n",
      "processing doc 763\n",
      "processing doc 764\n",
      "processing doc 765\n",
      "processing doc 766\n",
      "processing doc 767\n",
      "processing doc 768\n",
      "processing doc 769\n",
      "processing doc 770\n",
      "processing doc 771\n",
      "processing doc 772\n",
      "processing doc 773\n",
      "processing doc 774\n",
      "processing doc 775\n",
      "processing doc 776\n",
      "processing doc 777\n",
      "processing doc 778\n",
      "processing doc 779\n",
      "processing doc 780\n",
      "processing doc 781\n",
      "processing doc 782\n",
      "processing doc 783\n",
      "processing doc 784\n",
      "processing doc 785\n",
      "processing doc 786\n",
      "processing doc 787\n",
      "processing doc 788\n",
      "processing doc 789\n",
      "processing doc 790\n",
      "processing doc 791\n",
      "processing doc 792\n",
      "processing doc 793\n",
      "processing doc 794\n",
      "processing doc 795\n",
      "processing doc 796\n",
      "processing doc 797\n",
      "processing doc 798\n",
      "processing doc 799\n",
      "processing doc 800\n",
      "processing doc 801\n",
      "processing doc 802\n",
      "processing doc 803\n",
      "processing doc 804\n",
      "processing doc 805\n",
      "processing doc 806\n",
      "processing doc 807\n",
      "processing doc 808\n",
      "processing doc 809\n",
      "processing doc 810\n",
      "processing doc 811\n",
      "processing doc 812\n",
      "processing doc 813\n",
      "processing doc 814\n",
      "processing doc 815\n",
      "processing doc 816\n",
      "processing doc 817\n",
      "processing doc 818\n",
      "processing doc 819\n",
      "processing doc 820\n",
      "processing doc 821\n",
      "processing doc 822\n",
      "processing doc 823\n",
      "processing doc 824\n",
      "processing doc 825\n",
      "processing doc 826\n",
      "processing doc 827\n",
      "processing doc 828\n",
      "processing doc 829\n",
      "processing doc 830\n",
      "processing doc 831\n",
      "processing doc 832\n",
      "processing doc 833\n",
      "processing doc 834\n",
      "processing doc 835\n",
      "processing doc 836\n",
      "processing doc 837\n",
      "processing doc 838\n",
      "processing doc 839\n",
      "processing doc 840\n",
      "processing doc 841\n",
      "processing doc 842\n",
      "processing doc 843\n",
      "processing doc 844\n",
      "processing doc 845\n",
      "processing doc 846\n",
      "processing doc 847\n",
      "processing doc 848\n",
      "processing doc 849\n",
      "processing doc 850\n",
      "processing doc 851\n",
      "processing doc 852\n",
      "processing doc 853\n",
      "processing doc 854\n",
      "processing doc 855\n",
      "processing doc 856\n",
      "processing doc 857\n",
      "processing doc 858\n",
      "processing doc 859\n",
      "processing doc 860\n",
      "processing doc 861\n",
      "processing doc 862\n",
      "processing doc 863\n",
      "processing doc 864\n",
      "processing doc 865\n",
      "processing doc 866\n",
      "processing doc 867\n",
      "processing doc 868\n",
      "processing doc 869\n",
      "processing doc 870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing doc 871\n",
      "processing doc 872\n",
      "processing doc 873\n",
      "processing doc 874\n",
      "processing doc 875\n",
      "processing doc 876\n",
      "processing doc 877\n",
      "processing doc 878\n",
      "processing doc 879\n",
      "processing doc 880\n",
      "processing doc 881\n",
      "processing doc 882\n",
      "processing doc 883\n",
      "processing doc 884\n",
      "processing doc 885\n",
      "processing doc 886\n",
      "processing doc 887\n",
      "processing doc 888\n",
      "processing doc 889\n",
      "processing doc 890\n",
      "processing doc 891\n",
      "processing doc 892\n",
      "processing doc 893\n",
      "processing doc 894\n",
      "processing doc 895\n",
      "processing doc 896\n",
      "processing doc 897\n",
      "processing doc 898\n",
      "processing doc 899\n",
      "processing doc 900\n",
      "processing doc 901\n",
      "processing doc 902\n",
      "processing doc 903\n",
      "processing doc 904\n",
      "processing doc 905\n",
      "processing doc 906\n",
      "processing doc 907\n",
      "processing doc 908\n",
      "processing doc 909\n",
      "processing doc 910\n",
      "processing doc 911\n",
      "processing doc 912\n",
      "processing doc 913\n",
      "processing doc 914\n",
      "processing doc 915\n",
      "processing doc 916\n",
      "processing doc 917\n",
      "processing doc 918\n",
      "processing doc 919\n",
      "processing doc 920\n",
      "processing doc 921\n",
      "processing doc 922\n",
      "processing doc 923\n",
      "processing doc 924\n",
      "processing doc 925\n",
      "processing doc 926\n",
      "processing doc 927\n",
      "processing doc 928\n",
      "processing doc 929\n",
      "processing doc 930\n",
      "processing doc 931\n",
      "processing doc 932\n",
      "processing doc 933\n",
      "processing doc 934\n",
      "processing doc 935\n",
      "processing doc 936\n",
      "processing doc 937\n",
      "processing doc 938\n",
      "processing doc 939\n",
      "processing doc 940\n",
      "processing doc 941\n",
      "processing doc 942\n",
      "processing doc 943\n",
      "processing doc 944\n",
      "processing doc 945\n",
      "processing doc 946\n",
      "processing doc 947\n",
      "processing doc 948\n",
      "processing doc 949\n",
      "processing doc 950\n",
      "processing doc 951\n",
      "processing doc 952\n",
      "processing doc 953\n",
      "processing doc 954\n",
      "processing doc 955\n",
      "processing doc 956\n",
      "processing doc 957\n",
      "processing doc 958\n",
      "processing doc 959\n",
      "processing doc 960\n",
      "processing doc 961\n",
      "processing doc 962\n",
      "processing doc 963\n",
      "processing doc 964\n",
      "processing doc 965\n",
      "processing doc 966\n",
      "processing doc 967\n",
      "processing doc 968\n",
      "processing doc 969\n",
      "processing doc 970\n",
      "processing doc 971\n",
      "processing doc 972\n",
      "processing doc 973\n",
      "processing doc 974\n",
      "processing doc 975\n",
      "processing doc 976\n",
      "processing doc 977\n",
      "processing doc 978\n",
      "processing doc 979\n",
      "processing doc 980\n",
      "processing doc 981\n",
      "processing doc 982\n",
      "processing doc 983\n",
      "processing doc 984\n",
      "processing doc 985\n",
      "processing doc 986\n",
      "processing doc 987\n",
      "processing doc 988\n",
      "processing doc 989\n",
      "processing doc 990\n",
      "processing doc 991\n",
      "processing doc 992\n",
      "processing doc 993\n",
      "processing doc 994\n",
      "processing doc 995\n",
      "processing doc 996\n",
      "processing doc 997\n",
      "processing doc 998\n",
      "processing doc 999\n",
      "processing doc 1000\n",
      "processing doc 1001\n",
      "processing doc 1002\n",
      "processing doc 1003\n",
      "processing doc 1004\n",
      "processing doc 1005\n",
      "processing doc 1006\n",
      "processing doc 1007\n",
      "processing doc 1008\n",
      "processing doc 1009\n",
      "processing doc 1010\n",
      "processing doc 1011\n",
      "processing doc 1012\n",
      "processing doc 1013\n",
      "processing doc 1014\n",
      "processing doc 1015\n",
      "processing doc 1016\n",
      "processing doc 1017\n",
      "processing doc 1018\n",
      "processing doc 1019\n",
      "processing doc 1020\n",
      "processing doc 1021\n",
      "processing doc 1022\n",
      "processing doc 1023\n",
      "processing doc 1024\n",
      "processing doc 1025\n",
      "processing doc 1026\n",
      "processing doc 1027\n",
      "processing doc 1028\n",
      "processing doc 1029\n",
      "processing doc 1030\n",
      "processing doc 1031\n",
      "processing doc 1032\n",
      "processing doc 1033\n",
      "processing doc 1034\n",
      "processing doc 1035\n",
      "processing doc 1036\n",
      "processing doc 1037\n",
      "processing doc 1038\n",
      "processing doc 1039\n",
      "processing doc 1040\n",
      "processing doc 1041\n",
      "processing doc 1042\n",
      "processing doc 1043\n",
      "processing doc 1044\n",
      "processing doc 1045\n",
      "processing doc 1046\n",
      "processing doc 1047\n",
      "processing doc 1048\n",
      "processing doc 1049\n",
      "processing doc 1050\n",
      "processing doc 1051\n",
      "processing doc 1052\n",
      "processing doc 1053\n",
      "processing doc 1054\n",
      "processing doc 1055\n",
      "processing doc 1056\n",
      "processing doc 1057\n",
      "processing doc 1058\n",
      "processing doc 1059\n",
      "processing doc 1060\n",
      "processing doc 1061\n",
      "processing doc 1062\n",
      "processing doc 1063\n",
      "processing doc 1064\n",
      "processing doc 1065\n",
      "processing doc 1066\n",
      "processing doc 1067\n",
      "processing doc 1068\n",
      "processing doc 1069\n",
      "processing doc 1070\n",
      "processing doc 1071\n",
      "processing doc 1072\n",
      "processing doc 1073\n",
      "processing doc 1074\n",
      "processing doc 1075\n",
      "processing doc 1076\n",
      "processing doc 1077\n",
      "processing doc 1078\n",
      "processing doc 1079\n",
      "processing doc 1080\n",
      "processing doc 1081\n",
      "processing doc 1082\n",
      "processing doc 1083\n",
      "processing doc 1084\n",
      "processing doc 1085\n",
      "processing doc 1086\n",
      "processing doc 1087\n",
      "processing doc 1088\n",
      "processing doc 1089\n",
      "processing doc 1090\n",
      "processing doc 1091\n",
      "processing doc 1092\n",
      "processing doc 1093\n",
      "processing doc 1094\n",
      "processing doc 1095\n",
      "processing doc 1096\n",
      "processing doc 1097\n",
      "processing doc 1098\n",
      "processing doc 1099\n",
      "processing doc 1100\n",
      "processing doc 1101\n",
      "processing doc 1102\n",
      "processing doc 1103\n",
      "processing doc 1104\n",
      "processing doc 1105\n",
      "processing doc 1106\n",
      "processing doc 1107\n",
      "processing doc 1108\n",
      "processing doc 1109\n",
      "processing doc 1110\n",
      "processing doc 1111\n",
      "processing doc 1112\n",
      "processing doc 1113\n",
      "processing doc 1114\n",
      "processing doc 1115\n",
      "processing doc 1116\n",
      "processing doc 1117\n",
      "processing doc 1118\n",
      "processing doc 1119\n",
      "processing doc 1120\n",
      "processing doc 1121\n",
      "processing doc 1122\n",
      "processing doc 1123\n",
      "processing doc 1124\n",
      "processing doc 1125\n",
      "processing doc 1126\n",
      "processing doc 1127\n",
      "processing doc 1128\n",
      "processing doc 1129\n",
      "processing doc 1130\n",
      "processing doc 1131\n",
      "processing doc 1132\n",
      "processing doc 1133\n",
      "processing doc 1134\n",
      "processing doc 1135\n",
      "processing doc 1136\n",
      "processing doc 1137\n",
      "processing doc 1138\n",
      "processing doc 1139\n",
      "processing doc 1140\n",
      "processing doc 1141\n",
      "processing doc 1142\n",
      "processing doc 1143\n",
      "processing doc 1144\n",
      "processing doc 1145\n",
      "processing doc 1146\n",
      "processing doc 1147\n",
      "processing doc 1148\n",
      "processing doc 1149\n",
      "processing doc 1150\n",
      "processing doc 1151\n",
      "processing doc 1152\n",
      "processing doc 1153\n",
      "processing doc 1154\n",
      "processing doc 1155\n",
      "processing doc 1156\n",
      "processing doc 1157\n",
      "processing doc 1158\n",
      "processing doc 1159\n",
      "processing doc 1160\n",
      "processing doc 1161\n",
      "processing doc 1162\n",
      "processing doc 1163\n",
      "processing doc 1164\n",
      "processing doc 1165\n",
      "processing doc 1166\n",
      "processing doc 1167\n",
      "processing doc 1168\n",
      "processing doc 1169\n",
      "processing doc 1170\n",
      "processing doc 1171\n",
      "processing doc 1172\n",
      "processing doc 1173\n",
      "processing doc 1174\n",
      "processing doc 1175\n",
      "processing doc 1176\n",
      "processing doc 1177\n",
      "processing doc 1178\n",
      "processing doc 1179\n",
      "processing doc 1180\n",
      "processing doc 1181\n",
      "processing doc 1182\n",
      "processing doc 1183\n",
      "processing doc 1184\n",
      "processing doc 1185\n",
      "processing doc 1186\n",
      "processing doc 1187\n",
      "processing doc 1188\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = []\n",
    "for i,passage in enumerate(train_passages):\n",
    "    print(\"processing doc\", i)\n",
    "    embeddings = get_bert_embeddings(str(passage))\n",
    "    train_embeddings.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_passages = np.load(\"processed_data/test_passage_list.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing doc 0\n",
      "processing doc 1\n",
      "processing doc 2\n",
      "processing doc 3\n",
      "processing doc 4\n",
      "processing doc 5\n",
      "processing doc 6\n",
      "processing doc 7\n",
      "processing doc 8\n",
      "processing doc 9\n",
      "processing doc 10\n",
      "processing doc 11\n",
      "processing doc 12\n",
      "processing doc 13\n",
      "processing doc 14\n",
      "processing doc 15\n",
      "processing doc 16\n",
      "processing doc 17\n",
      "processing doc 18\n",
      "processing doc 19\n",
      "processing doc 20\n",
      "processing doc 21\n",
      "processing doc 22\n",
      "processing doc 23\n",
      "processing doc 24\n",
      "processing doc 25\n",
      "processing doc 26\n",
      "processing doc 27\n",
      "processing doc 28\n",
      "processing doc 29\n",
      "processing doc 30\n",
      "processing doc 31\n",
      "processing doc 32\n",
      "processing doc 33\n",
      "processing doc 34\n",
      "processing doc 35\n",
      "processing doc 36\n",
      "processing doc 37\n",
      "processing doc 38\n",
      "processing doc 39\n",
      "processing doc 40\n",
      "processing doc 41\n",
      "processing doc 42\n",
      "processing doc 43\n",
      "processing doc 44\n",
      "processing doc 45\n",
      "processing doc 46\n",
      "processing doc 47\n",
      "processing doc 48\n",
      "processing doc 49\n",
      "processing doc 50\n",
      "processing doc 51\n",
      "processing doc 52\n",
      "processing doc 53\n",
      "processing doc 54\n",
      "processing doc 55\n",
      "processing doc 56\n",
      "processing doc 57\n",
      "processing doc 58\n",
      "processing doc 59\n",
      "processing doc 60\n",
      "processing doc 61\n",
      "processing doc 62\n",
      "processing doc 63\n",
      "processing doc 64\n",
      "processing doc 65\n",
      "processing doc 66\n",
      "processing doc 67\n",
      "processing doc 68\n",
      "processing doc 69\n",
      "processing doc 70\n",
      "processing doc 71\n",
      "processing doc 72\n",
      "processing doc 73\n",
      "processing doc 74\n",
      "processing doc 75\n",
      "processing doc 76\n",
      "processing doc 77\n",
      "processing doc 78\n",
      "processing doc 79\n",
      "processing doc 80\n",
      "processing doc 81\n",
      "processing doc 82\n",
      "processing doc 83\n",
      "processing doc 84\n",
      "processing doc 85\n",
      "processing doc 86\n",
      "processing doc 87\n",
      "processing doc 88\n",
      "processing doc 89\n",
      "processing doc 90\n",
      "processing doc 91\n",
      "processing doc 92\n",
      "processing doc 93\n",
      "processing doc 94\n",
      "processing doc 95\n",
      "processing doc 96\n",
      "processing doc 97\n",
      "processing doc 98\n",
      "processing doc 99\n",
      "processing doc 100\n",
      "processing doc 101\n",
      "processing doc 102\n",
      "processing doc 103\n",
      "processing doc 104\n",
      "processing doc 105\n",
      "processing doc 106\n",
      "processing doc 107\n",
      "processing doc 108\n",
      "processing doc 109\n",
      "processing doc 110\n",
      "processing doc 111\n",
      "processing doc 112\n",
      "processing doc 113\n",
      "processing doc 114\n",
      "processing doc 115\n",
      "processing doc 116\n",
      "processing doc 117\n",
      "processing doc 118\n",
      "processing doc 119\n",
      "processing doc 120\n",
      "processing doc 121\n",
      "processing doc 122\n",
      "processing doc 123\n",
      "processing doc 124\n",
      "processing doc 125\n",
      "processing doc 126\n",
      "processing doc 127\n",
      "processing doc 128\n",
      "processing doc 129\n",
      "processing doc 130\n",
      "processing doc 131\n",
      "processing doc 132\n"
     ]
    }
   ],
   "source": [
    "test_embeddings = []\n",
    "for i,passage in enumerate(test_passages):\n",
    "    print(\"processing doc\", i)\n",
    "    embeddings = get_bert_embeddings(str(passage))\n",
    "    test_embeddings.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1189 133 768 768\n"
     ]
    }
   ],
   "source": [
    "print(len(train_embeddings), len(test_embeddings), len(train_embeddings[0][0]), len(test_embeddings[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_positive_pairs = np.load(\"./processed_data/train_positive_pairs.npy\")\n",
    "total_negative_pairs = np.load(\"./processed_data/train_negative_pairs.npy\")\n",
    "test_positive_pairs = np.load(\"./processed_data/test_positive_pairs.npy\")\n",
    "test_negative_pairs = np.load(\"./processed_data/test_negative_pairs.npy\")\n",
    "train_positive_pairs = total_positive_pairs[0:1000]\n",
    "train_negative_pairs = total_negative_pairs[0:1000]\n",
    "valid_positive_pairs = total_positive_pairs[1000:]\n",
    "valid_negative_pairs = total_negative_pairs[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "X_valid = []\n",
    "Y_valid = []\n",
    "X_test = []\n",
    "Y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc_pairs in enumerate(train_positive_pairs):\n",
    "    for coref_pair in doc_pairs:\n",
    "        sample = [i, coref_pair[0][0], coref_pair[0][1], coref_pair[1][0], coref_pair[1][1]]\n",
    "        X_train.append(sample)\n",
    "        Y_train.append([1])\n",
    "for i, doc_pairs in enumerate(train_negative_pairs):\n",
    "    for coref_pair in doc_pairs:\n",
    "        sample = [i, coref_pair[0][0], coref_pair[0][1], coref_pair[1][0], coref_pair[1][1]]\n",
    "        X_train.append(sample)\n",
    "        Y_train.append([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc_pairs in enumerate(valid_positive_pairs):\n",
    "    for coref_pair in doc_pairs:\n",
    "        sample = [i, coref_pair[0][0], coref_pair[0][1], coref_pair[1][0], coref_pair[1][1]]\n",
    "        X_valid.append(sample)\n",
    "        Y_valid.append([1])\n",
    "for i, doc_pairs in enumerate(valid_negative_pairs):\n",
    "    for coref_pair in doc_pairs:\n",
    "        sample = [i, coref_pair[0][0], coref_pair[0][1], coref_pair[1][0], coref_pair[1][1]]\n",
    "        X_valid.append(sample)\n",
    "        Y_valid.append([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc_pairs in enumerate(test_positive_pairs):\n",
    "    for coref_pair in doc_pairs:\n",
    "        sample = [i, coref_pair[0][0], coref_pair[0][1], coref_pair[1][0], coref_pair[1][1]]\n",
    "        X_test.append(sample)\n",
    "        Y_test.append([1])\n",
    "for i, doc_pairs in enumerate(test_negative_pairs):\n",
    "    for coref_pair in doc_pairs:\n",
    "        sample = [i, coref_pair[0][0], coref_pair[0][1], coref_pair[1][0], coref_pair[1][1]]\n",
    "        X_test.append(sample)\n",
    "        Y_test.append([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_idx = list(np.random.permutation(len(X_train)))\n",
    "X_train = np.array([X_train[i] for i in shuffled_idx])\n",
    "Y_train = np.array([Y_train[i] for i in shuffled_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_idx = list(np.random.permutation(len(X_valid)))\n",
    "X_valid = np.array([X_train[i] for i in shuffled_idx])\n",
    "Y_valid = np.array([Y_train[i] for i in shuffled_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_idx = list(np.random.permutation(len(X_test)))\n",
    "X_test = np.array([X_test[i] for i in shuffled_idx])\n",
    "Y_test = np.array([Y_test[i] for i in shuffled_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_featues_from_pairs(X_batch, embeddings):\n",
    "    batch_embeddings = []\n",
    "    for x in X_batch:\n",
    "        doc_id, a_start, a_end, b_start, b_end = x \n",
    "        doc_emb = embeddings[doc_id]\n",
    "        emb_a = torch.sum(doc_emb[a_start:a_end+1], 0)\n",
    "        emb_b = torch.sum(doc_emb[b_start:b_end+1], 0)\n",
    "        emb_dot = torch.mul(emb_a, emb_a)\n",
    "        emb_cat   = torch.cat((emb_a, emb_b), 0)\n",
    "        emb   = torch.cat((emb_cat, emb_dot), 0)\n",
    "        batch_embeddings.append(emb)\n",
    "    return torch.stack(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(prediction, truth):\n",
    "    confusion_vector = prediction / truth\n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(Y, y_preds):\n",
    "    y_actuals = torch.tensor(Y).type(torch.float32).to(device)\n",
    "    y_preds = y_preds.to(device)\n",
    "    tp, fp, tn, fn = confusion(y_preds, y_actuals)\n",
    "    precision = tp*1.0/(tp+fp)\n",
    "    recall   = tp*1.0/(tp+fn)\n",
    "    f1 = 2.0*precision*recall/(precision+recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, criterion, batch_size, X_data, Y_data, embeddings, mode=\"train\"):\n",
    "    \n",
    "    if(mode == \"train\"):\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    running_corrects = 0\n",
    "    shuffled_idx = list(np.random.permutation(len(X_data)))\n",
    "    minibatch_idxs = np.array_split(shuffled_idx, len(shuffled_idx)/batch_size) \n",
    "    ones = 0\n",
    "    zeros = 0\n",
    "    y_preds_all = torch.Tensor().to(device)\n",
    "    y_shuffled_all = torch.Tensor().to(device)\n",
    "    for minibatch_ids in minibatch_idxs:\n",
    "        x_batch_raw = X_data[minibatch_ids]\n",
    "        x_batch = get_featues_from_pairs(x_batch_raw, embeddings)\n",
    "        y_batch = torch.tensor(Y_data[minibatch_ids]).type(torch.float32)\n",
    "        x_batch = Variable(x_batch).to(device)\n",
    "        y_batch = Variable(y_batch).to(device)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        if(mode == \"train\"):\n",
    "            y_hat = model(x_batch)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                y_hat = model(x_batch)\n",
    "        \n",
    "        y_preds = (y_hat > 0.7).type(torch.float32)\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        corrects = float(torch.sum(y_preds == y_batch).item())\n",
    "        running_corrects += corrects\n",
    "        ones  += torch.sum(y_preds==1).item()\n",
    "        zeros +=  torch.sum(y_preds==0).item()\n",
    "        if(mode == \"train\"):\n",
    "            loss.backward()\n",
    "            opt.step()    \n",
    "        losses.append(loss.item())\n",
    "        y_preds_all = torch.cat((y_preds_all,y_preds))\n",
    "        y_shuffled_all = torch.cat((y_shuffled_all,y_batch))\n",
    "    print(\"ones and zeros\", ones, zeros)\n",
    "    accuracy = running_corrects * 1.0 / len(shuffled_idx)\n",
    "    avg_loss = sum(losses) * 1.0 / len(losses)\n",
    "    precision, recall, F1 = calculate_f1(y_shuffled_all, y_preds_all)\n",
    "    return avg_loss, accuracy, precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, embeddings):\n",
    "    model.eval()\n",
    "    idxs = range(0, len(X))\n",
    "    minibatch_idxs = np.array_split(idxs, len(idxs)/batch_size)\n",
    "    y_preds_all = torch.Tensor().to(device)\n",
    "    y_hats_all = torch.Tensor().to(device)\n",
    "    for minibatch_ids in minibatch_idxs:\n",
    "        x_batch_raw = X[minibatch_ids]\n",
    "        x_batch = get_featues_from_pairs(x_batch_raw, embeddings)\n",
    "        x_batch = Variable(x_batch).to(device)\n",
    "        opt.zero_grad()\n",
    "        with torch.no_grad():\n",
    "                y_hats = model(x_batch)\n",
    "        y_preds = (y_hats > 0.9).type(torch.float32)\n",
    "        y_preds_all = torch.cat((y_preds_all,y_preds))\n",
    "        y_hats_all = torch.cat((y_preds_all,y_hats))\n",
    "    return y_preds_all, y_hats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, embeddings):\n",
    "    y_preds, y_hats = predict(model, X, embeddings)\n",
    "    Y = Variable(torch.tensor(Y).type(torch.float32)).to(device)\n",
    "    corrects = float(torch.sum(y_preds == Y).item())\n",
    "    accuracy = corrects * 1.0 / Y.size()[0]\n",
    "    return accuracy,y_preds, y_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(768*3, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout = self.dout(h1)\n",
    "        a2 = self.fc2(dout)\n",
    "        h2 = self.relu2(a2)\n",
    "        a3 = self.out(h2)\n",
    "        y = self.out_act(a3)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "net.apply(init_weights)\n",
    "opt = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "batch_size = 1024\n",
    "num_epochs = 30\n",
    "criterion = nn.BCELoss() #pos_weight=torch.tensor([0.8,1]), pos_weight=torch.tensor([0.8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ EPOCH 0 / 30\n",
      "ones and zeros 13004 830730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones and zeros 20515 676993\n",
      "Train loss and accuracy, prf1:  0.19487680378907507 0.9482324998162928 0.9244455276626858 0.43356499474189564 0.5902858832500738\n",
      "Val loss and accuracy, prf1:  0.10245514153974697 0.9622556300429529 0.9244455276626858 0.43356499474189564 0.5902858832500738\n",
      "================ EPOCH 1 / 30\n",
      "ones and zeros 26413 817321\n",
      "ones and zeros 26433 671075\n",
      "Train loss and accuracy, prf1:  0.10160854835411758 0.963676940836804 0.9464684296144971 0.5719445841525308 0.7130174563591024\n",
      "Val loss and accuracy, prf1:  0.07489565611651465 0.9711272128778451 0.9464684296144971 0.5719445841525308 0.7130174563591024\n",
      "================ EPOCH 2 / 30\n",
      "ones and zeros 30810 812924\n",
      "ones and zeros 26555 670953\n",
      "Train loss and accuracy, prf1:  0.08443512863061987 0.9690186717614794 0.9700244774995292 0.588884824653651 0.7328619998008451\n",
      "Val loss and accuracy, prf1:  0.0640199831392884 0.9730770113030962 0.9700244774995292 0.588884824653651 0.7328619998008451\n",
      "================ EPOCH 3 / 30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-363-00c66ecd483d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"================ EPOCH\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_loss_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-357-a87376fc0929>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, opt, criterion, batch_size, X_data, Y_data, embeddings, mode)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mminibatch_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch_idxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx_batch_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mminibatch_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_featues_from_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mminibatch_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-347-1ab87e8199b2>\u001b[0m in \u001b[0;36mget_featues_from_pairs\u001b[0;34m(X_batch, embeddings)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdoc_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0memb_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma_end\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0memb_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb_end\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0memb_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_seq = []\n",
    "val_loss_seq = []\n",
    "train_acc_seq = []\n",
    "val_acc_seq = []\n",
    "for e in range(num_epochs):\n",
    "    print(\"================ EPOCH\", e, \"/\", num_epochs)\n",
    "    train_loss, train_acc, precision, recall, f1 = train_epoch(net, opt, criterion, batch_size, X_train, Y_train, train_embeddings,\"train\")\n",
    "    val_loss, val_acc, precision, recall, f1 = train_epoch(net, opt, criterion, batch_size, X_valid, Y_valid, train_embeddings, \"validation\")\n",
    "    train_loss_seq.append(train_loss)\n",
    "    train_acc_seq.append(train_acc)\n",
    "    val_loss_seq.append(val_loss)\n",
    "    val_acc_seq.append(val_acc)\n",
    "    print(\"Train loss and accuracy, prf1: \", train_loss, train_acc,precision, recall, f1)\n",
    "    print(\"Val loss and accuracy, prf1: \", val_loss, val_acc,precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"processed_data/negative_samples_run.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=2304, out_features=512, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (dout): Dropout(p=0.4)\n",
       "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (out_act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"processed_data/second_run.pth\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds, y_hats = predict(model, X_test, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, y_preds, y_hats = evaluate(model, X_test, Y_test, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_y_preds = y_preds.view(1, y_preds.size()[0]).to(\"cpu\").numpy()[0].astype(int)\n",
    "numpy_y_actuals = Y_test.reshape(1, Y_test.shape[0])[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7580023907557445, 0.5984062074027472, 0.6688151880932849)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_f1(Y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels(numpy_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[138980   3520]\n",
      " [  2982   6555]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2ebb6ef780>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = np.array([0,1])\n",
    "plot_confusion_matrix(numpy_y_actuals, numpy_y_preds, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
